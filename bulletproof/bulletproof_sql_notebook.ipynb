{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_csv(file_path='./parking-geo.csv'):\n",
    "    # let's be memory efficient when loading our data\n",
    "    dtypes_dict = \\\n",
    "    {\n",
    "        'ticket_number': np.int32,\n",
    "        'violation_location': str,\n",
    "        'license_plate_number': str,\n",
    "        'license_plate_state': 'category',\n",
    "        'license_plate_type': 'category',\n",
    "        'zipcode': str,\n",
    "        'violation_code': 'category',\n",
    "        'violation_description': 'category',\n",
    "        'unit': 'category',\n",
    "        'unit_description': 'category',\n",
    "        'vehicle_make': 'category',\n",
    "        'fine_level1_amount': np.int32,\n",
    "        'fine_level2_amount': np.int32,\n",
    "        'current_amount_due': np.float64,\n",
    "        'total_payments': np.float64,\n",
    "        'ticket_queue': 'category',\n",
    "        'notice_level': 'category',\n",
    "        'hearing_disposition': 'category',\n",
    "        'notice_number': np.int32,\n",
    "        'dismissal_reason': str,\n",
    "        'officer': str,\n",
    "        'address': str,\n",
    "        'license_hash': str,\n",
    "        'year': np.int32,\n",
    "        'month': 'category',\n",
    "        'hour': 'category',\n",
    "        'penalty': np.float64,\n",
    "        'ward': 'category',\n",
    "        'geocode_accuracy': np.float64,\n",
    "        'geocode_accuracy_type': 'category',\n",
    "        'geocoded_address': str,\n",
    "        'geocoded_lng': str,\n",
    "        'geocoded_lat': str,\n",
    "        'geocoded_city': 'category',\n",
    "        'geocoded_state': 'category'\n",
    "    }\n",
    "    #still better than strings\n",
    "    parse_dates_list = \\\n",
    "    [\n",
    "        'issue_date',\n",
    "        'ticket_queue_date',\n",
    "    ]\n",
    "    \n",
    "    # read csv into memory -- this takes quite a while\n",
    "    df = pd.read_csv(file_path, dtype=dtypes_dict, parse_dates=parse_dates_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df_raw, min_year = 1995, max_year = 2019):\n",
    "    df_filtered = df_raw[\n",
    "        (df_raw['year'] > min_year) & (df_raw['year'] < max_year) & \n",
    "        (df_raw['geocode_accuracy_type'].isin(['rooftop', 'range_interpolation', 'intersection', 'point'])) & \n",
    "        (df_raw['geocode_accuracy'] > 0.7) &\n",
    "        (df_raw['geocoded_city'] == 'Chicago')\n",
    "    ]\n",
    "    # not used\n",
    "    # df_filtered_na = df_filtered[df_filtered['ward'].isnull()]\n",
    "    df_filtered = df_filtered[df_filtered['ward'].notnull()]\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_summary_stats(df_raw, min_year = 1995, max_year = 2019, filter_and_group_data=True):\n",
    "    \n",
    "    # private helper function\n",
    "    def rank_series(series):\n",
    "        out_series = series.rank(ascending=False)\n",
    "        return out_series\n",
    "    \n",
    "    if filter_and_group_data:\n",
    "        df_filtered = filter_data(df_raw, min_year, max_year)\n",
    "    else:\n",
    "        df_filtered = df_raw\n",
    "\n",
    "    # calculate base dataframes\n",
    "    df_dict = dict()\n",
    "    df_dict['filtered'] = df_filtered\n",
    "    df_dict['police_tickets'] = df_filtered[\n",
    "        df_filtered['unit_description'].isin(['CPD', 'CPD-Other', 'CPD-Airport'])\n",
    "    ]\n",
    "    df_dict['contested_tickets'] = df_filtered[\n",
    "        df_filtered['hearing_disposition'].isin(['Liable', 'Not Liable'])\n",
    "    ]\n",
    "    df_dict['paid_tickets'] = df_filtered[\n",
    "        df_filtered['ticket_queue'] == 'Paid'\n",
    "    ]\n",
    "    df_dict['dismissed_tickets'] = df_filtered[\n",
    "        df_filtered['ticket_queue'] == 'Dismissed'\n",
    "    ]\n",
    "    df_dict['seized_or_suspended_tickets'] = df_filtered[\n",
    "        df_filtered['notice_level'].isin(['SEIZ', 'DLS'])\n",
    "    ]\n",
    "    df_dict['bankruptcy_tickets'] = df_filtered[\n",
    "        df_filtered['ticket_queue'] == 'Bankruptcy'\n",
    "    ]\n",
    "\n",
    "    # group dataframes by ward\n",
    "    gb_dict = dict()\n",
    "    \n",
    "    for key in df_dict:\n",
    "        if filter_and_group_data:\n",
    "            gb_dict[key] = df_dict[key].groupby('ward')\n",
    "        else:\n",
    "            gb_dict[key] = df_dict[key]\n",
    "\n",
    "    # calculate the different stats\n",
    "    out_dict = dict()\n",
    "    ticket_count = gb_dict['filtered']['ticket_number'].count()\n",
    "    out_dict['ticket_count'] = ticket_count\n",
    "    out_dict['current_amount_due'] = gb_dict['filtered']['current_amount_due'].sum()\n",
    "    out_dict['fine_level1_amount'] = gb_dict['filtered']['fine_level1_amount'].sum()\n",
    "    out_dict['total_payments'] = gb_dict['filtered']['total_payments'].sum()\n",
    "    out_dict['avg_per_ticket'] = out_dict['fine_level1_amount']/ticket_count\n",
    "    out_dict['paid_pct'] = out_dict['total_payments']/(out_dict['current_amount_due']+out_dict['total_payments'])\n",
    "    out_dict['police_ticket_count'] = gb_dict['police_tickets']['ticket_number'].count()\n",
    "    out_dict['police_ticket_count_pct'] = out_dict['police_ticket_count'] / ticket_count\n",
    "    out_dict['contested_ticket_count'] = gb_dict['contested_tickets']['ticket_number'].count()\n",
    "    out_dict['contested_ticket_count_pct'] = out_dict['contested_ticket_count'] / ticket_count\n",
    "    out_dict['paid_ticket_count'] = gb_dict['paid_tickets']['ticket_number'].count()\n",
    "    out_dict['paid_ticket_count_pct'] = out_dict['paid_ticket_count'] / ticket_count\n",
    "    out_dict['dismissed_ticket_count'] = gb_dict['dismissed_tickets']['ticket_number'].count()\n",
    "    out_dict['dismissed_ticket_count_pct'] = out_dict['dismissed_ticket_count'] / ticket_count\n",
    "    out_dict['seized_or_suspended_ticket_count'] = gb_dict['seized_or_suspended_tickets']['ticket_number'].count()\n",
    "    out_dict['seized_or_suspended_ticket_count_pct'] = out_dict['seized_or_suspended_ticket_count'] / ticket_count\n",
    "    out_dict['bankruptcy_ticket_count'] = gb_dict['bankruptcy_tickets']['ticket_number'].count()\n",
    "    out_dict['bankruptcy_ticket_count_pct'] = out_dict['bankruptcy_ticket_count'] / ticket_count\n",
    "\n",
    "    # calculate ranks; combine and format output dataframe\n",
    "    if filter_and_group_data:\n",
    "        df_out = pd.DataFrame()\n",
    "        for key in out_dict:\n",
    "            df_out[key] = out_dict[key]\n",
    "            df_out[key+'_rank'] = rank_series(out_dict[key]).astype(int)\n",
    "        df_out.index = df_out.index.astype(int)\n",
    "        df_out = df_out.sort_index()\n",
    "\n",
    "        return df_out\n",
    "    else:\n",
    "        series_out = pd.Series()\n",
    "        for key in out_dict:\n",
    "            series_out[key] = out_dict[key]\n",
    "        return series_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_top_level_summaries(df_in, columns):\n",
    "    df_out = calculate_summary_stats(df_in, min_year=None, max_year=None, filter_and_group_data=False)\n",
    "    return df_out[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_top_5_per_year(df_raw, min_year=1995, max_year=2019):\n",
    "    df_filtered = filter_data(df_raw, min_year, max_year)\n",
    "    gb_in = df_filtered[['ticket_number','year','violation_code']].groupby(['year','violation_code'])\n",
    "    top_5_list = []\n",
    "    for year, new_df in gb_in.count().groupby('year'):\n",
    "        top_5_list.append(new_df.nlargest(5, columns='ticket_number'))\n",
    "\n",
    "    df_out = pd.concat(top_5_list)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 21s, sys: 2min 43s, total: 12min 5s\n",
      "Wall time: 12min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# takes quite a while...\n",
    "df = read_in_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 3min 6s, total: 4min 29s\n",
      "Wall time: 5min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_1996to2018 = calculate_summary_stats(df, min_year=1995, max_year=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.6 s, sys: 13.3 s, total: 33.9 s\n",
      "Wall time: 29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_2013to2017 = calculate_summary_stats(df, min_year=2012, max_year=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.94 s, sys: 2.66 s, total: 12.6 s\n",
      "Wall time: 7.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_top_five_2013to2017 = calculate_top_5_per_year(df, min_year=2012, max_year=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 86 µs, sys: 1e+03 ns, total: 87 µs\n",
      "Wall time: 90.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "col_list = df_2013to2017.columns.tolist()\n",
    "final_col_list = [x for x in col_list if x[-4:] != '_pct' and x[-5:] != '_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53 s, sys: 2min 22s, total: 3min 15s\n",
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_top_level_summaries = calculate_top_level_summaries(df, final_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1996to2018.to_csv('df_1996to2018.csv')\n",
    "df_2013to2017.to_csv('df_2013to2017.csv')\n",
    "df_top_five_2013to2017.to_csv('df_top_five_2013to2017')\n",
    "df_top_level_summaries.to_csv('df_top_level_summaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = pd.read_csv('./wardstotals.csv', index_col='ward').sort_index(ascending=True)\n",
    "df_check5yr = pd.read_csv('./wardstotals5yr.csv', index_col='ward').sort_index(ascending=True)\n",
    "df_1996to2018_check = df_check[col_list]\n",
    "df_2013to2017_check = df_check5yr[col_list]\n",
    "wardstotals_sql_minus_pandas = df_1996to2018_check - df_1996to2018\n",
    "wardstotals5yr_sql_minus_pandas = df_2013to2017_check - df_2013to2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wardstotals5yr_sql_minus_pandas.to_csv('./wardstotals5yr_sql_minus_pandas.csv')\n",
    "wardstotals_sql_minus_pandas.to_csv('./wardstotals_sql_minus_pandas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
